{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RunFullDataSet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3C1p1jMuVdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b10321f-af81-4995-923e-3d097568a6a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5VaJGC7OYMu"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/DCGAN-tensorflow-master')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn1NRiLapCyR",
        "outputId": "43530003-421b-4cd4-a8ef-82b56fad4a5c"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip list | grep tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "mesh-tensorflow               0.1.12             \n",
            "tensorflow                    1.15.2             \n",
            "tensorflow-datasets           4.0.1              \n",
            "tensorflow-estimator          1.15.1             \n",
            "tensorflow-gan                2.0.0              \n",
            "tensorflow-gcs-config         2.5.0              \n",
            "tensorflow-hub                0.12.0             \n",
            "tensorflow-metadata           1.0.0              \n",
            "tensorflow-probability        0.7.0              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gej4TqR3z1vj",
        "outputId": "ff683e34-5934-4c27-c1d7-dc463ea60f85"
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.15.2\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /tensorflow-1.15.2/python3.7\n",
            "Requires: astor, keras-applications, tensorboard, gast, protobuf, opt-einsum, six, grpcio, absl-py, tensorflow-estimator, wrapt, keras-preprocessing, numpy, termcolor, google-pasta, wheel\n",
            "Required-by: stable-baselines, magenta, kapre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2HQSXaCt9Ry",
        "outputId": "7638dd8d-57df-4c27-b40c-6e34e7524375"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuqsRu_D0NL4",
        "outputId": "e35d6be6-3a14-4859-e5b0-3b785fdf2029"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 3777316251186376277, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 5745564642716255928\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 13934142235117669991\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14949928141\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 1367101304833448278\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xezwzKcZo2IO"
      },
      "source": [
        "import os\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from model import DCGAN\n",
        "from utils import pp, visualize, to_json, show_all_variables, expand_path, timestamp\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_integer(\"epoch\", 500, \"Epoch to train [25]\")\n",
        "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
        "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
        "flags.DEFINE_float(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
        "flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch images [64]\")\n",
        "flags.DEFINE_integer(\"input_height\", 96, \"The size of image to use (will be center cropped). [108]\")\n",
        "flags.DEFINE_integer(\"input_width\", None, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
        "flags.DEFINE_integer(\"output_height\", 64, \"The size of the output images to produce [64]\")\n",
        "flags.DEFINE_integer(\"output_width\", None, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
        "flags.DEFINE_string(\"dataset\", \"IncarnationFaces\", \"The name of dataset [celebA, mnist, lsun]\")\n",
        "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
        "flags.DEFINE_string(\"data_dir\", \"./data\", \"path to datasets [e.g. $HOME/data]\")\n",
        "flags.DEFINE_string(\"out_dir\", \"./out\", \"Root directory for outputs [e.g. $HOME/out]\")\n",
        "flags.DEFINE_string(\"out_name\", \"\", \"Folder (under out_root_dir) for all outputs. Generated automatically if left blank []\")\n",
        "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
        "flags.DEFINE_string(\"sample_dir\", \"samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
        "flags.DEFINE_boolean(\"train\", True, \"True for training, False for testing [False]\")\n",
        "flags.DEFINE_boolean(\"crop\", True, \"True for training, False for testing [False]\")\n",
        "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
        "flags.DEFINE_boolean(\"export\", False, \"True for exporting with new batch size\")\n",
        "flags.DEFINE_boolean(\"freeze\", False, \"True for exporting with new batch size\")\n",
        "flags.DEFINE_integer(\"max_to_keep\", 1, \"maximum number of checkpoints to keep\")\n",
        "flags.DEFINE_integer(\"sample_freq\", 500, \"sample every this many iterations\")\n",
        "flags.DEFINE_integer(\"ckpt_freq\", 200, \"save checkpoint every this many iterations\")\n",
        "flags.DEFINE_integer(\"z_dim\", 100, \"dimensions of z\")\n",
        "flags.DEFINE_string(\"z_dist\", \"uniform_signed\", \"'normal01' or 'uniform_unsigned' or uniform_signed\")\n",
        "flags.DEFINE_boolean(\"G_img_sum\", False, \"Save generator image summaries in log\")\n",
        "# flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "def main(_):\n",
        "  pp.pprint(flags.FLAGS.__flags)\n",
        "  \n",
        "  # expand user name and environment variables\n",
        "  FLAGS.data_dir = expand_path(FLAGS.data_dir)\n",
        "  FLAGS.out_dir = expand_path(FLAGS.out_dir)\n",
        "  FLAGS.out_name = expand_path(FLAGS.out_name)\n",
        "  FLAGS.checkpoint_dir = expand_path(FLAGS.checkpoint_dir)\n",
        "  FLAGS.sample_dir = expand_path(FLAGS.sample_dir)\n",
        "\n",
        "  if FLAGS.output_height is None: FLAGS.output_height = FLAGS.input_height\n",
        "  if FLAGS.input_width is None: FLAGS.input_width = FLAGS.input_height\n",
        "  if FLAGS.output_width is None: FLAGS.output_width = FLAGS.output_height\n",
        "\n",
        "  # output folders\n",
        "  if FLAGS.out_name == \"\":\n",
        "      FLAGS.out_name = '{} - {}'.format( FLAGS.data_dir.split('/')[-1],FLAGS.dataset)  # penultimate folder of path\n",
        "      FLAGS.out_name += ' - x{}.z{}.{}.y{}.b{}'.format(FLAGS.input_width, FLAGS.z_dim, FLAGS.z_dist, FLAGS.output_width, FLAGS.batch_size)\n",
        "\n",
        "\n",
        "  FLAGS.out_dir = os.path.join(FLAGS.out_dir, FLAGS.out_name)\n",
        "  FLAGS.checkpoint_dir = os.path.join(FLAGS.out_dir, FLAGS.checkpoint_dir)\n",
        "  FLAGS.sample_dir = os.path.join(FLAGS.out_dir, FLAGS.sample_dir)\n",
        "\n",
        "  if not os.path.exists(FLAGS.checkpoint_dir): os.makedirs(FLAGS.checkpoint_dir)\n",
        "  if not os.path.exists(FLAGS.sample_dir): os.makedirs(FLAGS.sample_dir)\n",
        "\n",
        "  with open(os.path.join(FLAGS.out_dir, 'FLAGS.json'), 'w') as f:\n",
        "    flags_dict = {k:FLAGS[k].value for k in FLAGS}\n",
        "    json.dump(flags_dict, f, indent=4, sort_keys=True, ensure_ascii=False)\n",
        "  \n",
        "\n",
        "  #gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
        "  run_config = tf.ConfigProto()\n",
        "  run_config.gpu_options.allow_growth=True\n",
        "\n",
        "  with tf.Session(config=run_config) as sess:\n",
        "    dcgan = DCGAN(\n",
        "          sess,\n",
        "          input_width=FLAGS.input_width,\n",
        "          input_height=FLAGS.input_height,\n",
        "          output_width=FLAGS.output_width,\n",
        "          output_height=FLAGS.output_height,\n",
        "          batch_size=FLAGS.batch_size,\n",
        "          sample_num=FLAGS.batch_size,\n",
        "          z_dim=FLAGS.z_dim,\n",
        "          dataset_name=FLAGS.dataset,\n",
        "          input_fname_pattern=FLAGS.input_fname_pattern,\n",
        "          crop=FLAGS.crop,\n",
        "          checkpoint_dir=FLAGS.checkpoint_dir,\n",
        "          sample_dir=FLAGS.sample_dir,\n",
        "          data_dir=FLAGS.data_dir,\n",
        "          out_dir=FLAGS.out_dir,\n",
        "          max_to_keep=FLAGS.max_to_keep)\n",
        "\n",
        "    show_all_variables()\n",
        "\n",
        "    if FLAGS.train:\n",
        "      dcgan.train(FLAGS)\n",
        "    else:\n",
        "      load_success, load_counter = dcgan.load(FLAGS.checkpoint_dir)\n",
        "      if not load_success:\n",
        "        raise Exception(\"Checkpoint not found in \" + FLAGS.checkpoint_dir)\n",
        "\n",
        "\n",
        "    # to_json(\"./web/js/layers.js\", [dcgan.h0_w, dcgan.h0_b, dcgan.g_bn0],\n",
        "    #                 [dcgan.h1_w, dcgan.h1_b, dcgan.g_bn1],\n",
        "    #                 [dcgan.h2_w, dcgan.h2_b, dcgan.g_bn2],\n",
        "    #                 [dcgan.h3_w, dcgan.h3_b, dcgan.g_bn3],\n",
        "    #                 [dcgan.h4_w, dcgan.h4_b, None])\n",
        "\n",
        "    # Below is codes for visualization\n",
        "      if FLAGS.export:\n",
        "        export_dir = os.path.join(FLAGS.checkpoint_dir, 'export_b'+str(FLAGS.batch_size))\n",
        "        dcgan.save(export_dir, load_counter, ckpt=True, frozen=False)\n",
        "\n",
        "      if FLAGS.freeze:\n",
        "        export_dir = os.path.join(FLAGS.checkpoint_dir, 'frozen_b'+str(FLAGS.batch_size))\n",
        "        dcgan.save(export_dir, load_counter, ckpt=False, frozen=True)\n",
        "\n",
        "      if FLAGS.visualize:\n",
        "        OPTION = 1\n",
        "        visualize(sess, dcgan, FLAGS, OPTION, FLAGS.sample_dir)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}